"""
Output rendering module for repo-to-prompt.

Generates Markdown context packs, JSONL chunks, and reports.
"""

from __future__ import annotations

import contextlib
import json
from datetime import datetime
from pathlib import Path

from .config import Chunk, FileInfo, OutputMode, ScanStats
from .ranker import FileRanker
from .scanner import generate_tree
from .utils import read_file_safe


class ContextPackRenderer:
    """
    Renders a Markdown context pack for LLM prompting.

    Structure:
    1. REPO OVERVIEW - Summary, purpose, key info
    2. DIRECTORY TREE - Visual structure
    3. KEY FILES - READMEs, configs, entrypoints
    4. CODE MAP - Per-language module listing
    5. FILE CONTENTS - Chunked content with citations
    """

    def __init__(
        self,
        root_path: Path,
        files: list[FileInfo],
        chunks: list[Chunk],
        ranker: FileRanker,
        stats: ScanStats,
        max_total_tokens: int | None = None,
    ):
        """
        Initialize the renderer.

        Args:
            root_path: Repository root path
            files: List of scanned files
            chunks: List of content chunks
            ranker: File ranker with manifest info
            stats: Scan statistics
            max_total_tokens: Maximum total tokens in output
        """
        self.root_path = root_path
        self.files = files
        self.chunks = chunks
        self.ranker = ranker
        self.stats = stats
        self.max_total_tokens = max_total_tokens

        # Organize files by type
        self._readme_files = [f for f in files if f.is_readme]
        self._config_files = [f for f in files if f.is_config and not f.is_readme]
        self._doc_files = [f for f in files if f.is_doc and not f.is_readme]

    def render(self) -> str:
        """Render the complete context pack."""
        sections = []

        # Header
        sections.append(self._render_header())

        # Overview
        sections.append(self._render_overview())

        # Directory tree
        sections.append(self._render_tree())

        # Key files summary
        sections.append(self._render_key_files())

        # Code map
        sections.append(self._render_code_map())

        # File contents
        sections.append(self._render_contents())

        return "\n\n".join(filter(None, sections))

    def _render_header(self) -> str:
        """Render the document header."""
        repo_name = self.root_path.name
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        return f"""# Repository Context Pack: {repo_name}

> Generated by repo-to-prompt on {timestamp}
> Files: {self.stats.files_included} | Chunks: {self.stats.chunks_created} | Size: {self.stats.total_bytes_included:,} bytes

---"""

    def _render_overview(self) -> str:
        """Render the repository overview section."""
        lines = ["## ðŸ“‹ Repository Overview"]

        # Try to extract README content for summary
        readme_content = ""
        if self._readme_files:
            with contextlib.suppress(Exception):
                readme_content, _ = read_file_safe(
                    self._readme_files[0].path,
                    max_bytes=4000
                )

        # Project info from manifests
        manifest_info = self.ranker.get_manifest_info()

        if manifest_info.get("name"):
            lines.append(f"\n**Project:** {manifest_info['name']}")

        if manifest_info.get("description"):
            lines.append(f"\n**Description:** {manifest_info['description']}")

        # Detected languages
        self.ranker.get_detected_languages()
        lang_stats = self.stats.languages_detected

        if lang_stats:
            lang_summary = ", ".join(
                f"{lang} ({count})"
                for lang, count in sorted(lang_stats.items(), key=lambda x: -x[1])[:5]
            )
            lines.append(f"\n**Languages:** {lang_summary}")

        # Entrypoints
        entrypoints = self.ranker.get_entrypoints()
        if entrypoints:
            lines.append("\n**Entrypoints:**")
            for ep in sorted(entrypoints)[:10]:
                lines.append(f"- `{ep}`")

        # Build/test commands from package.json scripts
        scripts = manifest_info.get("scripts", {})
        if scripts:
            lines.append("\n**Available Commands:**")
            for cmd in ["build", "test", "start", "dev", "lint"]:
                if cmd in scripts:
                    lines.append(f"- `{cmd}`: `{scripts[cmd][:60]}...`" if len(scripts[cmd]) > 60 else f"- `{cmd}`: `{scripts[cmd]}`")

        # README excerpt
        if readme_content:
            # Get first meaningful section
            readme_lines = readme_content.split("\n")
            excerpt_lines = []
            in_content = False

            for line in readme_lines[:50]:
                # Skip badges and initial headers
                if line.strip() and not line.startswith("![") and not line.startswith("[!["):
                    in_content = True
                if in_content:
                    excerpt_lines.append(line)
                    if len(excerpt_lines) >= 15:
                        break

            if excerpt_lines:
                excerpt = "\n".join(excerpt_lines)
                lines.append(f"\n**README Excerpt:**\n\n{excerpt}")
                if len(readme_lines) > 50:
                    lines.append("\n*[README truncated...]*")

        return "\n".join(lines)

    def _render_tree(self) -> str:
        """Render the directory tree section."""
        # Highlight important files
        important_files = {
            f.relative_path for f in self.files
            if f.priority >= 0.8
        }

        tree = generate_tree(
            self.root_path,
            max_depth=4,
            include_files=True,
            files_to_highlight=important_files,
        )

        return f"""## ðŸ“ Directory Structure

```
{tree}
```

*â­ = Important file*"""

    def _render_key_files(self) -> str:
        """Render the key files summary section."""
        lines = ["## ðŸ”‘ Key Files"]

        # Group files by category
        categories = [
            ("Documentation", [f for f in self.files if f.is_doc][:5]),
            ("Configuration", [f for f in self.files if f.is_config][:5]),
            ("Entrypoints", [f for f in self.files if "entrypoint" in f.tags][:5]),
        ]

        for category, category_files in categories:
            if category_files:
                lines.append(f"\n### {category}")
                for f in category_files:
                    priority_str = f"({f.priority:.0%})" if f.priority else ""
                    lines.append(f"- `{f.relative_path}` {priority_str}")

        return "\n".join(lines)

    def _render_code_map(self) -> str:
        """Render the code map section (per-language module listing)."""
        lines = ["## ðŸ—ºï¸ Code Map"]

        # Group files by language
        files_by_lang: dict[str, list[FileInfo]] = {}
        for f in self.files:
            if f.language not in files_by_lang:
                files_by_lang[f.language] = []
            files_by_lang[f.language].append(f)

        # Sort languages by file count
        sorted_langs = sorted(
            files_by_lang.items(),
            key=lambda x: -len(x[1])
        )

        for lang, lang_files in sorted_langs[:5]:
            if lang in ("text", "markdown"):
                continue

            lines.append(f"\n### {lang.title()} ({len(lang_files)} files)")

            # Group by directory
            dirs: dict[str, list[FileInfo]] = {}
            for f in lang_files:
                dir_path = str(Path(f.relative_path).parent)
                if dir_path == ".":
                    dir_path = "(root)"
                if dir_path not in dirs:
                    dirs[dir_path] = []
                dirs[dir_path].append(f)

            for dir_path, dir_files in sorted(dirs.items())[:10]:
                lines.append(f"\n**{dir_path}/**")
                for f in sorted(dir_files, key=lambda x: x.path.name)[:10]:
                    lines.append(f"- `{f.path.name}`")
                if len(dir_files) > 10:
                    lines.append(f"- *...and {len(dir_files) - 10} more*")

        return "\n".join(lines)

    def _render_contents(self) -> str:
        """Render the file contents section with chunks."""
        lines = ["## ðŸ“„ File Contents"]

        # Group chunks by file
        chunks_by_file: dict[str, list[Chunk]] = {}
        for chunk in self.chunks:
            if chunk.path not in chunks_by_file:
                chunks_by_file[chunk.path] = []
            chunks_by_file[chunk.path].append(chunk)

        # Sort files by priority (from the original file list)
        file_priorities = {f.relative_path: f.priority for f in self.files}
        sorted_files = sorted(
            chunks_by_file.keys(),
            key=lambda p: (-file_priorities.get(p, 0), p)
        )

        total_tokens = 0

        for file_path in sorted_files:
            file_chunks = chunks_by_file[file_path]

            # Sort chunks by line number
            file_chunks.sort(key=lambda c: c.start_line)

            # Get file info
            file_info = next(
                (f for f in self.files if f.relative_path == file_path),
                None
            )

            lang = file_chunks[0].language if file_chunks else "text"
            priority = file_info.priority if file_info else 0.5

            lines.append(f"\n### `{file_path}`")
            lines.append(f"*Priority: {priority:.0%} | Language: {lang} | Chunks: {len(file_chunks)}*")

            for chunk in file_chunks:
                # Check token budget
                if self.max_total_tokens and total_tokens + chunk.token_estimate > self.max_total_tokens:
                    lines.append("\n*[Content truncated due to token limit]*")
                    return "\n".join(lines)

                total_tokens += chunk.token_estimate

                # Citation header
                lines.append(f"\n**Lines {chunk.start_line}-{chunk.end_line}:**")

                # Code block
                lines.append(f"```{lang}")
                lines.append(chunk.content.rstrip())
                lines.append("```")

        return "\n".join(lines)


class JSONLRenderer:
    """Renders chunks as JSONL for RAG/embedding."""

    def __init__(self, chunks: list[Chunk]):
        """
        Initialize the renderer.

        Args:
            chunks: List of chunks to render
        """
        self.chunks = chunks

    def render(self) -> str:
        """Render chunks as JSONL string."""
        lines = []
        for chunk in self.chunks:
            lines.append(json.dumps(chunk.to_dict(), ensure_ascii=False))
        return "\n".join(lines)

    def write(self, output_path: Path) -> None:
        """Write chunks to JSONL file."""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            for chunk in self.chunks:
                f.write(json.dumps(chunk.to_dict(), ensure_ascii=False))
                f.write("\n")


class ReportRenderer:
    """Renders the processing report as JSON."""

    def __init__(
        self,
        stats: ScanStats,
        config: dict,
        output_files: list[str],
    ):
        """
        Initialize the renderer.

        Args:
            stats: Scan statistics
            config: Configuration used
            output_files: List of generated output files
        """
        self.stats = stats
        self.config = config
        self.output_files = output_files

    def render(self) -> dict:
        """Render the report as a dictionary."""
        return {
            "generated_at": datetime.now().isoformat(),
            "stats": self.stats.to_dict(),
            "config": self.config,
            "output_files": self.output_files,
        }

    def write(self, output_path: Path) -> None:
        """Write report to JSON file."""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(self.render(), f, indent=2, ensure_ascii=False)


def render_context_pack(
    root_path: Path,
    files: list[FileInfo],
    chunks: list[Chunk],
    ranker: FileRanker,
    stats: ScanStats,
    max_total_tokens: int | None = None,
) -> str:
    """
    Convenience function to render a context pack.

    Args:
        root_path: Repository root path
        files: List of scanned files
        chunks: List of content chunks
        ranker: File ranker with manifest info
        stats: Scan statistics
        max_total_tokens: Maximum total tokens

    Returns:
        Rendered Markdown string
    """
    renderer = ContextPackRenderer(
        root_path=root_path,
        files=files,
        chunks=chunks,
        ranker=ranker,
        stats=stats,
        max_total_tokens=max_total_tokens,
    )
    return renderer.render()


def render_jsonl(chunks: list[Chunk]) -> str:
    """
    Convenience function to render chunks as JSONL.

    Args:
        chunks: List of chunks

    Returns:
        JSONL string
    """
    renderer = JSONLRenderer(chunks)
    return renderer.render()


def write_outputs(
    output_dir: Path,
    mode: OutputMode,
    context_pack: str,
    chunks: list[Chunk],
    stats: ScanStats,
    config: dict,
) -> list[str]:
    """
    Write all outputs to the output directory.

    Args:
        output_dir: Output directory path
        mode: Output mode
        context_pack: Rendered context pack
        chunks: List of chunks
        stats: Scan statistics
        config: Configuration used

    Returns:
        List of generated file paths
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    output_files = []

    # Write context pack
    if mode in (OutputMode.PROMPT, OutputMode.BOTH):
        context_path = output_dir / "context_pack.md"
        with open(context_path, "w", encoding="utf-8") as f:
            f.write(context_pack)
        output_files.append(str(context_path))

    # Write JSONL chunks
    if mode in (OutputMode.RAG, OutputMode.BOTH):
        jsonl_path = output_dir / "chunks.jsonl"
        jsonl_renderer = JSONLRenderer(chunks)
        jsonl_renderer.write(jsonl_path)
        output_files.append(str(jsonl_path))

    # Write report
    report_path = output_dir / "report.json"
    report_renderer = ReportRenderer(stats, config, output_files)
    report_renderer.write(report_path)
    output_files.append(str(report_path))

    return output_files
